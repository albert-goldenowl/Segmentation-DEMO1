# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'start_form.ui'
#
# Created by: PyQt5 UI code generator 5.15.9
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtGui import QImage
import cv2
import os
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import time
import onnxruntime as ort

frame_shape = (640, 480)
target_shape = (256, 256, 3)
half_width = target_shape[0] // 2
half_height = target_shape[1] // 2
x0 = frame_shape[0] // 2 - half_width
y0 = frame_shape[1] // 2 - half_height
x1 = frame_shape[0] // 2 + half_width
y1 = frame_shape[1] // 2 + half_height

def create_img(mask_output):
    r = np.zeros((256, 256), dtype=np.uint8)
    g = np.zeros((256, 256), dtype=np.uint8)
    b = np.zeros((256, 256), dtype=np.uint8)
    r[mask_output == 1] = 250
    r[mask_output == 2] = 36
    r[mask_output == 3] = 42
    r[mask_output == 4] = 115

    g[mask_output == 1] = 50
    g[mask_output == 2] = 179
    g[mask_output == 3] = 125
    g[mask_output == 4] = 51

    b[mask_output == 1] = 83
    b[mask_output == 2] = 83
    b[mask_output == 3] = 209
    b[mask_output == 4] = 128

    output = np.stack([b, g, r], axis=-1)
    return output
def create_img_bg(roi, mask_output):
    b, g, r = cv2.split(roi)
    r[mask_output == 1] = 250
    r[mask_output == 2] = 36
    r[mask_output == 3] = 42
    r[mask_output == 4] = 115

    g[mask_output == 1] = 50
    g[mask_output == 2] = 179
    g[mask_output == 3] = 125
    g[mask_output == 4] = 51

    b[mask_output == 1] = 83
    b[mask_output == 2] = 83
    b[mask_output == 3] = 209
    b[mask_output == 4] = 128

    output = np.stack([b, g, r], axis=-1)
    return output


class Ui_Dialog(object):
    def setupUi(self, Dialog):
        Dialog.setObjectName("Dialog")
        Dialog.resize(688, 622)
        Dialog.setStyleSheet("background-color:rgb(255, 255, 0)")
        self.label = QtWidgets.QLabel(Dialog)
        self.label.setGeometry(QtCore.QRect(60, 20, 571, 451))
        self.label.setText("")
        self.label.setPixmap(QtGui.QPixmap("val_images/212.jpg"))
        self.label.setObjectName("label")
        self.pushButton = QtWidgets.QPushButton(Dialog)
        self.pushButton.setGeometry(QtCore.QRect(550, 560, 131, 51))
        self.pushButton.setStyleSheet("QPushButton {\n"
"font: 18pt \"Bahnschrift Condensed\";\n"
"background-color:rgb(80, 64, 153);\n"
"color:white;\n"
"border-radius:12px;\n"
"}\n"
"QPushButton:hover{\n"
"background-color:rgb(160, 118, 249);\n"
"}\n"
"")
        self.pushButton.setObjectName("pushButton")

        self.retranslateUi(Dialog)
        QtCore.QMetaObject.connectSlotsByName(Dialog)
        self.load_image()

    def retranslateUi(self, Dialog):
        _translate = QtCore.QCoreApplication.translate
        Dialog.setWindowTitle(_translate("Dialog", "Webcam"))
        self.pushButton.setText(_translate("Dialog", "Back"))
    def load_image(self):
        cam = cv2.VideoCapture(0)
        ort_session = ort.InferenceSession('model.onnx')
        input_name = ort_session.get_inputs()[0].name
        output_name = ort_session.get_outputs()[0].name
        background = -1
        prev_time = 0 
        new_time = 0
        while True:
            ret, frame = cam.read()
            sample_window = frame[y0:y0+target_shape[1], x0:x0+target_shape[0]].copy()
            
            input_to_model = cv2.cvtColor(sample_window, cv2.COLOR_BGR2RGB)
            input_to_model = input_to_model.astype(np.float32) / 255.0
            input_to_model = np.expand_dims(input_to_model, axis=0)
            y_pred = ort_session.run([output_name], {input_name: input_to_model})
            res = np.argmax(y_pred[0][0], axis=-1)
            mask_output = create_img(res)
            cv2.rectangle(frame, (x0, y0), (x1, y1), (0, 255, 0), 2)
            if background == -1:
                cv2.putText(frame, 'Black mode', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1)
                
            else:
                cv2.putText(frame, 'Background mode', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1)
                mask_output = create_img_bg(sample_window, res)
            frame[y0:y0+target_shape[1], x0:x0+target_shape[0]] = mask_output
            frame = cv2.flip(frame, 1)
            new_time = time.time()
            fps = str(int(1 / (new_time - prev_time)))
            cv2.putText(frame, str(int(fps)), (5, 30), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 1)
            prev_time = new_time
            cv2.imshow('cam', frame)
            k = cv2.waitKey(1)
            if k == ord('c'):
                crf = -crf
            if k == ord('b'):
                background = -background
            if k == ord('q'):
                break

            image = QImage(frame, frame.shape[1], frame.shape[0], frame.strides[0], QImage.Format_RGB888)

            self.label.setPixmap(QtGui.QPixmap.fromImage(image))

if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    Dialog = QtWidgets.QDialog()
    ui = Ui_Dialog()

    ui.setupUi(Dialog)

    Dialog.show()
    sys.exit(app.exec_())
